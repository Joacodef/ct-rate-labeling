# Prompt Engineering Log (tiny tuning set with N=100)

## Dataset Definitions & Lineage
* **Tiny Tuning Set (`data/tiny_tuning_set.csv`)**: 
    * **Size:** N=100 reports.
    * **Origin:** Subset of the larger Tuning Set (stratified by the 5 most common labels).
* **Tuning / Validation Set (`data/tuning_set.csv`)**: 
    * **Size:** N=615 reports.
    * **Origin:** Derived from the `test_manual_train` partition of the original CT-RATE dataset, with duplicate reports removed to ensure unique validation.
    * **Characteristics:** Representative distribution. Used for final validation (Step 6).
---

## Step 1: Baseline (Zero-Shot)
**Date:** 2026-02-02

**Goal:** Establish baseline on the new N=100 stratified tiny tuning set.

**Command:**
```bash
python scripts/evaluate_prompt.py --config-name prompt_engineering \
        prompt=zero-shot_multi \
        api.model=gpt-5-nano \
        io.reports_csv=data/tiny_tuning_set.csv
```

### Aggregate Results (3 Runs)
* **Mean Macro F1:** 0.7895 Â± 0.0109
* **Stability Check:** 0.0109 (Target < 0.02) -> âœ… **PASS**

### Per-Label Detailed Metrics (Mean Â± Std Dev)
| Label | Precision | Recall | F1 Score | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Lung Opacity** | **0.5540 Â± 0.0142** ğŸš¨ | 0.9688 Â± 0.0000 | 0.7047 Â± 0.0115 | **Primary Failure:** Persistent hallucinations (high recall, low precision). |
| **Lymphadenopathy** | 0.9697 Â± 0.0429 | **0.3793 Â± 0.0488** âš ï¸ | 0.5439 Â± 0.0533 | **Low Recall:** Sensitivity remains weak. |
| **Pulm. Fibrotic Seq.** | 0.8473 Â± 0.0139 | 0.8571 Â± 0.0000 | 0.8521 Â± 0.0071 | Stable / good baseline. |
| Arterial wall calc. | 0.9245 Â± 0.0297 | 0.9012 Â± 0.0174 | 0.9127 Â± 0.0228 | Stable / strong baseline. |
| Lung nodule | 0.8767 Â± 0.0080 | 1.0000 Â± 0.0000 | 0.9343 Â± 0.0046 | Stable / strong baseline. |
| **MACRO AVERAGE** | **0.8344 Â± 0.0049** | **0.8213 Â± 0.0086** | **0.7895 Â± 0.0109** | |

### Conclusion
* **Action:** Proceed to Step 2 (Few-Shot).
* **Goal:** Reduce Lung Opacity false positives and improve Lymphadenopathy recall.


## Step 2: Few-Shot Check
**Date:** 2026-02-02

**Goal:** Test if few-shot examples improve the two weakest labels without hurting overall stability.

**Command:**
```bash
python scripts/evaluate_prompt.py --config-name prompt_engineering \
    prompt=3-shot_multi_v1 \
    api.model=gpt-5-nano \
    io.reports_csv=data/tiny_tuning_set.csv
```

### Aggregate Results (3 Runs)
* **Mean Macro F1:** 0.7677 Â± 0.0069
* **Stability Check:** 0.0069 (Target < 0.02) -> âœ… **PASS**

### Per-Label Detailed Metrics (Mean Â± Std Dev)
| Label | Precision | Recall | F1 Score | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Lung Opacity** | **0.5113 Â± 0.0142** ğŸš¨ | 0.9584 Â± 0.0148 | 0.6668 Â± 0.0156 | **Worse:** Precision dropped vs zero-shot; hallucinations persist. |
| **Lymphadenopathy** | 1.0000 Â± 0.0000 | **0.2988 Â± 0.0162** âš ï¸ | 0.4599 Â± 0.0195 | **Worse:** Recall decreased further. |
| **Pulm. Fibrotic Seq.** | 0.8410 Â± 0.0151 | 0.8810 Â± 0.0169 | 0.8605 Â± 0.0144 | Slight improvement. |
| Arterial wall calc. | 0.9477 Â± 0.0174 | 0.8889 Â± 0.0000 | 0.9173 Â± 0.0082 | Stable / strong baseline. |
| Lung nodule | 0.8767 Â± 0.0080 | 1.0000 Â± 0.0000 | 0.9343 Â± 0.0046 | Stable / strong baseline. |
| **MACRO AVERAGE** | **0.8354 Â± 0.0038** | **0.8054 Â± 0.0054** | **0.7677 Â± 0.0069** | |

### Conclusion
* **Action:** Discard `3-shot_multi_v1`; proceed to Step 3 (Negative Constraints).
* **Goal:** Add explicit constraints to reduce Lung Opacity false positives and recover Lymphadenopathy recall.


## Step 3: Example Tuning (v2)
**Date:** 2026-02-02

**Goal:** Add explicit negative constraints to reduce Lung Opacity false positives and improve Lymphadenopathy recall.

**Command:**
```bash
python scripts/evaluate_prompt.py --config-name prompt_engineering \
    prompt=3-shot_multi_v2 \
    api.model=gpt-5-nano \
    io.reports_csv=data/tiny_tuning_set.csv
```

### Aggregate Results (3 Runs)
* **Mean Macro F1:** 0.8346 Â± 0.0043
* **Stability Check:** 0.0043 (Target < 0.02) -> âœ… **PASS**

### Per-Label Detailed Metrics (Mean Â± Std Dev)
| Label | Precision | Recall | F1 Score | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Lung Opacity** | **0.6838 Â± 0.0121** ğŸ”¼ | 0.8334 Â± 0.0148 | 0.7512 Â± 0.0133 | **Improved:** Precision up significantly vs v1. |
| **Lymphadenopathy** | 0.9833 Â± 0.0236 | **0.6667 Â± 0.0430** ğŸ”¼ | 0.7938 Â± 0.0329 | **Improved:** Recall recovered strongly. |
| **Pulm. Fibrotic Seq.** | 0.8354 Â± 0.0066 | 0.7262 Â± 0.0337 | 0.7767 Â± 0.0223 | **Tradeoff:** F1 dropped vs v1. |
| Arterial wall calc. | 0.9328 Â± 0.0181 | 0.8519 Â± 0.0000 | 0.8904 Â± 0.0082 | Slight drop vs v1. |
| Lung nodule | 0.9307 Â± 0.0087 | 0.9926 Â± 0.0105 | 0.9605 Â± 0.0051 | Improved. |
| **MACRO AVERAGE** | **0.8732 Â± 0.0109** | **0.8141 Â± 0.0008** | **0.8346 Â± 0.0043** | |

### Conclusion
* **Action:** Keep `3-shot_multi_v2` as current best. Consider a v3 prompt before finalizing.
* **Goal:** If pursuing v3, target Pulm. Fibrotic Seq. recall without hurting Lung Opacity precision.


## Step 3.2: Constraint Refinement (v3)
**Date:** 2026-02-02

**Goal:** Tighten label rules (opacity/nodule/fibrotic sequela/lymphadenopathy) to reduce false positives and recover recall.

**Command:**
```bash
python scripts/evaluate_prompt.py --config-name prompt_engineering \
    prompt=3-shot_multi_v3 \
    api.model=gpt-5-nano \
    io.reports_csv=data/tiny_tuning_set.csv
```

### Aggregate Results (3 Runs)
* **Mean Macro F1:** 0.8934 Â± 0.0078
* **Stability Check:** 0.0078 (Target < 0.02) -> âœ… **PASS**

### Per-Label Detailed Metrics (Mean Â± Std Dev)
| Label | Precision | Recall | F1 Score | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Lung Opacity** | **0.7048 Â± 0.0176** ğŸ”¼ | 0.8438 Â± 0.0000 | 0.7679 Â± 0.0104 | **Improved:** Precision up vs v2. |
| **Lymphadenopathy** | 0.9563 Â± 0.0147 | **1.0000 Â± 0.0000** ğŸ”¼ | 0.9776 Â± 0.0077 | **Major improvement:** Recall perfect on tiny set. |
| **Pulm. Fibrotic Seq.** | 0.8609 Â± 0.0169 | 0.8095 Â± 0.0168 | 0.8344 Â± 0.0152 | **Recovered:** F1 up vs v2. |
| Arterial wall calc. | 0.9230 Â± 0.0024 | 0.8889 Â± 0.0302 | 0.9054 Â± 0.0169 | Slight improvement. |
| Lung nodule | 0.9712 Â± 0.0097 | 0.9926 Â± 0.0105 | 0.9817 Â± 0.0052 | Improved. |
| **MACRO AVERAGE** | **0.8832 Â± 0.0073** | **0.9070 Â± 0.0082** | **0.8934 Â± 0.0078** | |

### Conclusion
* **Action:** Promote `3-shot_multi_v3` as current best.
* **Goal:** Proceed to model upgrade checks (Step 5) before final validation.


## Step 4: Mode Check (Single vs Multi)
**Date:** 2026-02-02

**Goal:** Verify whether single-label mode improves performance vs multi-label mode.

**Command:**
```bash
python scripts/evaluate_prompt.py --config-name prompt_engineering \
    prompt=3-shot_multi_v3 \
    api.model=gpt-5-nano \
    io.reports_csv=data/tiny_tuning_set.csv \
    prompt.mode=single
```

### Aggregate Results (3 Runs)
* **Mean Macro F1:** 0.8729 Â± 0.0089
* **Stability Check:** 0.0089 (Target < 0.02) -> âœ… **PASS**

### Per-Label Detailed Metrics (Mean Â± Std Dev)
| Label | Precision | Recall | F1 Score | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Lung Opacity** | **0.6838 Â± 0.0071** | 0.8334 Â± 0.0148 | 0.7512 Â± 0.0073 | Slightly worse than multi. |
| **Lymphadenopathy** | 0.9459 Â± 0.0147 | **1.0000 Â± 0.0000** | 0.9722 Â± 0.0077 | Slightly worse than multi. |
| **Pulm. Fibrotic Seq.** | 0.8233 Â± 0.0060 | 0.8333 Â± 0.0337 | 0.8281 Â± 0.0198 | Slightly worse than multi. |
| Arterial wall calc. | 0.8760 Â± 0.0298 | 0.7778 Â± 0.0000 | 0.8237 Â± 0.0132 | Worse than multi. |
| Lung nodule | 0.9783 Â± 0.0000 | 1.0000 Â± 0.0000 | 0.9890 Â± 0.0000 | Slightly better than multi. |
| **MACRO AVERAGE** | **0.8615 Â± 0.0105** | **0.8889 Â± 0.0097** | **0.8729 Â± 0.0089** | |

### Conclusion
* **Action:** Stick with multi-label mode (`3-shot_multi_v3`).
* **Goal:** Proceed to model upgrade checks (Step 5) before final validation.


## Step 5.1: Model Upgrade Check (GPT-5 Mini)
**Date:** 2026-02-02

**Goal:** Test if a higher-capacity model improves performance enough to justify cost.

**Command:**
```bash
python scripts/evaluate_prompt.py --config-name prompt_engineering \
    prompt=3-shot_multi_v3 \
    api.model=gpt-5-mini \
    io.reports_csv=data/tiny_tuning_set.csv
```

### Aggregate Results (3 Runs)
* **Mean Macro F1:** 0.9123 Â± 0.0029
* **Stability Check:** 0.0029 (Target < 0.02) -> âœ… **PASS**

### Per-Label Detailed Metrics (Mean Â± Std Dev)
| Label | Precision | Recall | F1 Score | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Lung Opacity** | **0.6869 Â± 0.0038** | 0.8229 Â± 0.0148 | 0.7488 Â± 0.0083 | Slightly worse than nano v3. |
| **Lymphadenopathy** | 0.9667 Â± 0.0000 | **1.0000 Â± 0.0000** | 0.9831 Â± 0.0000 | Slightly better than nano v3. |
| **Pulm. Fibrotic Seq.** | 0.8404 Â± 0.0024 | 0.9405 Â± 0.0168 | 0.8876 Â± 0.0088 | Improved vs nano v3. |
| Arterial wall calc. | 0.9103 Â± 0.0146 | 1.0000 Â± 0.0000 | 0.9530 Â± 0.0080 | Improved vs nano v3. |
| Lung nodule | 0.9783 Â± 0.0000 | 1.0000 Â± 0.0000 | 0.9890 Â± 0.0000 | Slightly better than nano v3. |
| **MACRO AVERAGE** | **0.8765 Â± 0.0031** | **0.9527 Â± 0.0032** | **0.9123 Â± 0.0029** | |

### Conclusion
* **Action:** Not worth the ~5x cost for a modest +0.0189 macro F1 gain vs nano v3.
* **Goal:** Stick with `gpt-5-nano` for final validation.


## Step 5.2: Model Upgrade Check (GPT-5.1)
**Date:** 2026-02-02

**Goal:** Test if a much higher-capacity model improves performance enough to justify cost.

**Command:**
```bash
python scripts/evaluate_prompt.py --config-name prompt_engineering \
    prompt=3-shot_multi_v3 \
    api.model=gpt-5.1 \
    io.reports_csv=data/tiny_tuning_set.csv
```

### Aggregate Results (3 Runs)
* **Mean Macro F1:** 0.9180 Â± 0.0017
* **Stability Check:** 0.0017 (Target < 0.02) -> âœ… **PASS**

### Per-Label Detailed Metrics (Mean Â± Std Dev)
| Label | Precision | Recall | F1 Score | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Lung Opacity** | **0.6896 Â± 0.0038** | 0.8334 Â± 0.0148 | 0.7547 Â± 0.0083 | Slightly worse than nano v3. |
| **Lymphadenopathy** | 0.9667 Â± 0.0000 | **1.0000 Â± 0.0000** | 0.9831 Â± 0.0000 | Slightly better than nano v3. |
| **Pulm. Fibrotic Seq.** | 0.8387 Â± 0.0000 | 0.9286 Â± 0.0000 | 0.8814 Â± 0.0000 | Improved vs nano v3. |
| Arterial wall calc. | 0.9643 Â± 0.0000 | 1.0000 Â± 0.0000 | 0.9818 Â± 0.0000 | Improved vs nano v3. |
| Lung nodule | 0.9783 Â± 0.0000 | 1.0000 Â± 0.0000 | 0.9890 Â± 0.0000 | Slightly better than nano v3. |
| **MACRO AVERAGE** | **0.8875 Â± 0.0008** | **0.9524 Â± 0.0030** | **0.9180 Â± 0.0017** | |

### Conclusion
* **Action:** Not worth the ~25x cost for a modest +0.0246 macro F1 gain vs nano v3.
* **Goal:** Stick with `gpt-5-nano` for final validation.


## Step 6: Final Validation (Full Tuning Set)
**Date:** 2026-02-03

**Goal:** Validate the chosen config on the full tuning set (N=615).

**Command:**
```bash
python scripts/evaluate_prompt.py --config-name prompt_engineering \
    prompt=3-shot_multi_v3 \
    api.model=gpt-5-nano \
    io.reports_csv=data/tuning_set.csv
```

### Aggregate Results (3 Runs)
* **Mean Macro F1:** 0.8889 Â± 0.0017
* **Stability Check:** 0.0017 (Target < 0.02) -> âœ… **PASS**

### Per-Label Detailed Metrics (Mean Â± Std Dev)
| Label | Precision | Recall | F1 Score | Status |
| :--- | :--- | :--- | :--- | :--- |
| **Lung Opacity** | **0.7471 Â± 0.0089** | 0.8618 Â± 0.0025 | 0.8004 Â± 0.0061 | Improved vs tiny set. |
| **Lymphadenopathy** | 0.9642 Â± 0.0025 | **0.9694 Â± 0.0051** | 0.9668 Â± 0.0034 | Stable / strong. |
| **Pulm. Fibrotic Seq.** | 0.8986 Â± 0.0026 | 0.7889 Â± 0.0227 | 0.8400 Â± 0.0140 | Good, with recall as main limiter. |
| Arterial wall calc. | 0.8462 Â± 0.0049 | 0.8953 Â± 0.0082 | 0.8701 Â± 0.0063 | Slightly lower than tiny set. |
| Lung nodule | 0.9528 Â± 0.0001 | 0.9825 Â± 0.0017 | 0.9674 Â± 0.0009 | Strong / stable. |
| **MACRO AVERAGE** | **0.8817 Â± 0.0013** | **0.8996 Â± 0.0042** | **0.8889 Â± 0.0017** | |

### Conclusion
* **Action:** Finalize `gpt-5-nano` + `3-shot_multi_v3`.
* **Goal:** Ship / productionize with this configuration.